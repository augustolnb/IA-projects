{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##*Modelinho* Ok\n"
      ],
      "metadata": {
        "id": "AwqvxtyWVEDY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Bibliotecas\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from google.colab import drive\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "kd7U-3aeLu5m"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sZEvIpFSNvNH"
      },
      "outputs": [],
      "source": [
        "drive.mount('/content/drive')\n",
        "\n",
        "# Caminho da pasta raiz contendo as subpastas\n",
        "dataset = \"/content/drive/MyDrive/IA_Projects/Face_Recognition/faces_dataset/partial_dataset\"\n",
        "\n",
        "# Rotula dataset\n",
        "labels = []\n",
        "for foldername in os.listdir(dataset):\n",
        "    labels.append(foldername)\n",
        "labels = np.array(labels)\n",
        "#print(\"Número de rótulos encontrados:\", len(labels))\n",
        "#print(\"Rótulos encontrados:\", labels)\n",
        "#np.save(\"rotulos.npy\", labels)\n",
        "\n",
        "# Define numero de pessoas no dataset\n",
        "n_classes = len(labels)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                   shear_range=0.2, #cisalhamento - trans. geometrica que distorce a imagem e simula angulação em imagens reais 0.2rad\n",
        "                                   zoom_range=0.2,\n",
        "                                   horizontal_flip=True) # tecnica de espelhamento, serve para aumentar os dados e treinar o modelo para angulos diferentes\n",
        "\n",
        "num_samples = len(datagen.flow_from_directory(dataset, batch_size=16, shuffle=False).filenames)\n",
        "\n",
        "# Ajuste de formato das imagens\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    \n",
        "    dataset,\n",
        "    target_size=(112, 112),\n",
        "    batch_size=16,\n",
        "    shuffle=False,\n",
        "    class_mode='categorical')\n",
        "\n",
        "x, y = train_generator.next()\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kRlwql6uOKQy",
        "outputId": "f47e5c4e-07b8-45ae-dd16-3c003c285671"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2484 images belonging to 579 classes.\n",
            "Found 2484 images belonging to 579 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    # primeira camada convolucional\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(112, 112, 3)),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    # segunda camada convolucional\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    # terceira camada convolucional\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    # quarta camada convolucional\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(n_classes, activation='softmax')])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])"
      ],
      "metadata": {
        "id": "-I16C8MEOWXB"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train, batch_size=64, epochs=20, validation_data=(X_val, y_val))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "asjEnIQWOa7P",
        "outputId": "75a15fe4-9e2b-4f2c-91ed-e3c76b63bfcc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1/1 [==============================] - 1s 730ms/step - loss: 0.7455 - categorical_accuracy: 0.7500 - val_loss: 9.0982 - val_categorical_accuracy: 0.2500\n",
            "Epoch 2/20\n",
            "1/1 [==============================] - 1s 990ms/step - loss: 0.7187 - categorical_accuracy: 0.6667 - val_loss: 10.4374 - val_categorical_accuracy: 0.2500\n",
            "Epoch 3/20\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.7052 - categorical_accuracy: 0.6667 - val_loss: 11.4915 - val_categorical_accuracy: 0.2500\n",
            "Epoch 4/20\n",
            "1/1 [==============================] - 1s 692ms/step - loss: 0.5957 - categorical_accuracy: 0.6667 - val_loss: 12.2225 - val_categorical_accuracy: 0.5000\n",
            "Epoch 5/20\n",
            "1/1 [==============================] - 0s 384ms/step - loss: 0.7148 - categorical_accuracy: 0.5833 - val_loss: 12.5338 - val_categorical_accuracy: 0.2500\n",
            "Epoch 6/20\n",
            "1/1 [==============================] - 0s 406ms/step - loss: 0.4963 - categorical_accuracy: 0.8333 - val_loss: 12.8504 - val_categorical_accuracy: 0.2500\n",
            "Epoch 7/20\n",
            "1/1 [==============================] - 0s 352ms/step - loss: 0.3271 - categorical_accuracy: 0.8333 - val_loss: 13.6975 - val_categorical_accuracy: 0.5000\n",
            "Epoch 8/20\n",
            "1/1 [==============================] - 0s 358ms/step - loss: 0.2249 - categorical_accuracy: 0.9167 - val_loss: 14.4685 - val_categorical_accuracy: 0.5000\n",
            "Epoch 9/20\n",
            "1/1 [==============================] - 0s 381ms/step - loss: 0.3382 - categorical_accuracy: 0.9167 - val_loss: 15.6628 - val_categorical_accuracy: 0.5000\n",
            "Epoch 10/20\n",
            "1/1 [==============================] - 0s 364ms/step - loss: 0.3292 - categorical_accuracy: 0.9167 - val_loss: 16.9848 - val_categorical_accuracy: 0.2500\n",
            "Epoch 11/20\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.4052 - categorical_accuracy: 0.8333 - val_loss: 16.9354 - val_categorical_accuracy: 0.2500\n",
            "Epoch 12/20\n",
            "1/1 [==============================] - 0s 419ms/step - loss: 0.4360 - categorical_accuracy: 0.7500 - val_loss: 15.9900 - val_categorical_accuracy: 0.5000\n",
            "Epoch 13/20\n",
            "1/1 [==============================] - 0s 391ms/step - loss: 0.2113 - categorical_accuracy: 0.9167 - val_loss: 15.3468 - val_categorical_accuracy: 0.5000\n",
            "Epoch 14/20\n",
            "1/1 [==============================] - 0s 404ms/step - loss: 0.1857 - categorical_accuracy: 0.9167 - val_loss: 15.3601 - val_categorical_accuracy: 0.2500\n",
            "Epoch 15/20\n",
            "1/1 [==============================] - 0s 417ms/step - loss: 0.2544 - categorical_accuracy: 0.8333 - val_loss: 15.2345 - val_categorical_accuracy: 0.5000\n",
            "Epoch 16/20\n",
            "1/1 [==============================] - 0s 377ms/step - loss: 0.1155 - categorical_accuracy: 1.0000 - val_loss: 15.6797 - val_categorical_accuracy: 0.5000\n",
            "Epoch 17/20\n",
            "1/1 [==============================] - 0s 419ms/step - loss: 0.2030 - categorical_accuracy: 1.0000 - val_loss: 15.0297 - val_categorical_accuracy: 0.5000\n",
            "Epoch 18/20\n",
            "1/1 [==============================] - 0s 355ms/step - loss: 0.1025 - categorical_accuracy: 0.9167 - val_loss: 14.1151 - val_categorical_accuracy: 0.5000\n",
            "Epoch 19/20\n",
            "1/1 [==============================] - 0s 357ms/step - loss: 0.0446 - categorical_accuracy: 1.0000 - val_loss: 13.5766 - val_categorical_accuracy: 0.5000\n",
            "Epoch 20/20\n",
            "1/1 [==============================] - 0s 367ms/step - loss: 0.0695 - categorical_accuracy: 1.0000 - val_loss: 13.3236 - val_categorical_accuracy: 0.5000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f29dab662b0>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Faz as previsões no conjunto de teste\n",
        "y_pred = np.argmax(model.predict(X_val), axis=-1)\n",
        "\n",
        "# Cria a matriz de confusão\n",
        "cm = confusion_matrix(y_val, y_pred)\n",
        "print(cm)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "aItGEbvWO9a4",
        "outputId": "f47e7237-4842-43c9-d4c5-e354c93c45a1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 177ms/step\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-a3274d7c0a1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Cria a matriz de confusão\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mcm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    315\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m     \"\"\"\n\u001b[0;32m--> 317\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s is not supported\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m     96\u001b[0m             \"Classification metrics can't handle a mix of {0} and {1} targets\".format(\n\u001b[1;32m     97\u001b[0m                 \u001b[0mtype_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of multilabel-indicator and binary targets"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Reconhecimento facial com distancia euclidiana\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "UBS2CTMlWScw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este modelo é formado por duas redes neurais idênticas, que compartilham seus pesos e recebem duas imagens de entrada: uma imagem de referência e uma imagem de comparação. As imagens passam por camadas convolucionais e de pooling, e então são passadas para uma camada densa de embedding com tamanho embedding_dim. As embeddings resultantes de cada imagem são normalizadas para terem norma unitária.\n",
        "\n",
        "Finalmente, é calculada a distância euclidiana entre as embeddings resultantes das duas imagens. Este modelo pode ser treinado utilizando um conjunto de pares de imagens, onde cada par é rotulado com uma distância (0 se as imagens são iguais, 1 se são diferentes). O objetivo do treinamento é minimizar a perda da distância entre as embeddings em pares de imagens correspondentes e maximizá-la em pares de imagens não correspondentes."
      ],
      "metadata": {
        "id": "Kac__2XUWnRJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Lambda\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "# Definindo a função para calcular a distância euclidiana\n",
        "def euclidean_distance(vectors):\n",
        "    (featsA, featsB) = vectors\n",
        "    sumSquared = K.sum(K.square(featsA - featsB), axis=1, keepdims=True)\n",
        "    return K.sqrt(K.maximum(sumSquared, K.epsilon()))\n",
        "\n",
        "# Definindo o modelo\n",
        "def create_model(input_shape, embedding_dim):\n",
        "    input_shape = (input_shape[0], input_shape[1], 3)\n",
        "    input_a = Input(shape=input_shape)\n",
        "    input_b = Input(shape=input_shape)\n",
        "\n",
        "    # Camadas convolucionais e de pooling\n",
        "    x = Conv2D(32, (3, 3), activation='relu')(input_a)\n",
        "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "    x = Conv2D(64, (3, 3), activation='relu')(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(embedding_dim, activation='relu')(x)\n",
        "    embeddings_a = Lambda(lambda x: K.l2_normalize(x, axis=1))(x)\n",
        "\n",
        "    x = Conv2D(32, (3, 3), activation='relu')(input_b)\n",
        "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "    x = Conv2D(64, (3, 3), activation='relu')(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(embedding_dim, activation='relu')(x)\n",
        "    embeddings_b = Lambda(lambda x: K.l2_normalize(x, axis=1))(x)\n",
        "\n",
        "    # Calculando a distância euclidiana entre as embeddings\n",
        "    distance = Lambda(euclidean_distance)([embeddings_a, embeddings_b])\n",
        "\n",
        "    # Definindo o modelo final\n",
        "    model = Model(inputs=[input_a, input_b], outputs=distance)\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "jCpn7iqDWNu5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Reconhecimento facial com distancia de mahalanobis\n"
      ],
      "metadata": {
        "id": "3CtMgUnaWets"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Neste exemplo, a distância de Mahalanobis é calculada dentro da função triplet_loss, que é utilizada como função de perda do modelo. Note que a função mahalanobis_dist é utilizada para calcular a distância entre as embeddings. Além disso, foi necessário importar a classe LedoitWolf do módulo sklearn.covariance para calcular a matriz de covariância empírica.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "IP7WDb9OWW3Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.covariance import LedoitWolf\n",
        "\n",
        "def mahalanobis_dist(x1, x2):\n",
        "    # Calcula a matriz de covariância\n",
        "    cov = LedoitWolf().fit(x1).covariance_\n",
        "    # Calcula a matriz de covariância inversa\n",
        "    cov_inv = np.linalg.inv(cov)\n",
        "    # Calcula a distância de Mahalanobis entre os dois vetores\n",
        "    dist = np.sqrt(np.dot(np.dot((x1 - x2), cov_inv), (x1 - x2).T))\n",
        "    return dist\n",
        "\n",
        "# Define o modelo\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(altura, largura, canais)))\n",
        "model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
        "model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
        "model.add(tf.keras.layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
        "model.add(tf.keras.layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(512, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(embedding_size, activation=None))\n",
        "\n",
        "# Define a função de loss\n",
        "def triplet_loss(y_true, y_pred, alpha=0.2):\n",
        "    # Separa as embeddings em âncora, positivo e negativo\n",
        "    anchor, positive, negative = tf.split(y_pred, 3, axis=1)\n",
        "    # Calcula a distância entre a âncora e o positivo\n",
        "    pos_dist = mahalanobis_dist(anchor, positive)\n",
        "    # Calcula a distância entre a âncora e o negativo\n",
        "    neg_dist = mahalanobis_dist(anchor, negative)\n",
        "    # Calcula a diferença entre as distâncias e adiciona uma margem\n",
        "    basic_loss = tf.reduce_mean(pos_dist - neg_dist + alpha)\n",
        "    # Limita o valor mínimo da loss a 0\n",
        "    loss = tf.maximum(basic_loss, 0.0)\n",
        "    return loss\n",
        "\n",
        "# Compila o modelo\n",
        "model.compile(optimizer='adam', loss=triplet_loss)\n",
        "\n",
        "# Treina o modelo\n",
        "history = model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(x_val, y_val))\n"
      ],
      "metadata": {
        "id": "Vyr-yzofWXN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Códigos úteis\n"
      ],
      "metadata": {
        "id": "rq6HYlR-VJeZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este código irá percorrer cada pasta no diretório do dataset e carregar cada imagem em um array numpy com a forma (112, 112, 3). Em seguida, armazena todas as matrizes de pixel em um array numpy com a forma (número de pastas, 112, 112, 3), e finalmente, salva o array numpy em um arquivo chamado \"dataset.npy\".\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HzM4dI8eVSI8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "# Definir o tamanho das imagens\n",
        "width = 112\n",
        "height = 112\n",
        "\n",
        "# Caminho para o diretório do dataset\n",
        "data_dir = \"/caminho/para/o/seu/dataset\"\n",
        "\n",
        "# Lista de todas as pastas no diretório do dataset\n",
        "folders = os.listdir(data_dir)\n",
        "\n",
        "# Inicializar o array numpy com zeros\n",
        "data = np.zeros((len(folders), width, height, 3), dtype=np.uint8)\n",
        "\n",
        "# Loop através de cada pasta e carregar cada imagem em um array numpy\n",
        "for i, folder in enumerate(folders):\n",
        "    # Lista de todas as imagens na pasta\n",
        "    images = os.listdir(os.path.join(data_dir, folder))\n",
        "    # Loop através de cada imagem na pasta e carregá-la em um array numpy\n",
        "    for j, image_name in enumerate(images):\n",
        "        # Caminho para a imagem\n",
        "        image_path = os.path.join(data_dir, folder, image_name)\n",
        "        # Carregar a imagem usando a biblioteca Pillow\n",
        "        image = Image.open(image_path)\n",
        "        # Redimensionar a imagem para o tamanho desejado\n",
        "        image = image.resize((width, height))\n",
        "        # Converter a imagem em um array numpy\n",
        "        image = np.array(image)\n",
        "        # Armazenar o array numpy no array de dados\n",
        "        data[i, :, :, j] = image\n",
        "\n",
        "# Salvar o array numpy em um arquivo\n",
        "np.save(\"dataset.npy\", data)\n"
      ],
      "metadata": {
        "id": "3tUK1JAHVP_E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Abaixo está um exemplo de código em Python utilizando a biblioteca GitPython para fazer o push automático dos arquivos:\n",
        "\n"
      ],
      "metadata": {
        "id": "kaQk53IeVc8F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import git\n",
        "\n",
        "# Diretório com os arquivos a serem enviados\n",
        "path_to_repo = '/path/to/repo'\n",
        "\n",
        "# Inicializa o repositório Git\n",
        "repo = git.Repo(path_to_repo)\n",
        "\n",
        "# Adiciona os arquivos ao staging\n",
        "repo.git.add('--all')\n",
        "\n",
        "# Faz o commit com uma mensagem de descrição\n",
        "repo.git.commit('-m', 'Adiciona arquivos de dataset')\n",
        "\n",
        "# Faz o push dos arquivos para o repositório remoto\n",
        "origin = repo.remote(name='origin')\n",
        "origin.push()\n"
      ],
      "metadata": {
        "id": "Bv60OJ6-Vdsv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para começar a usar o Git LFS, você precisa instalar o Git LFS em sua máquina local. Para isso, siga as instruções na documentação oficial: https://git-lfs.github.com/.\n",
        "\n",
        "Depois de instalar o Git LFS, você precisará configurá-lo em seu repositório. Você pode fazer isso usando o seguinte comando:"
      ],
      "metadata": {
        "id": "8pVUjiRsVpus"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "git lfs install\n",
        "git lfs track \"*.extensão_do_arquivo\"\n",
        "git lfs track \"*.jpg\"\n",
        "git lfs track \"*.png\"\n",
        "git lfs track \"*.mp4\"\n"
      ],
      "metadata": {
        "id": "E61hHjPEVqd9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Existem algumas opções para disponibilizar seu dataset de forma pública no Google Colab:\n",
        "\n",
        "Armazenar o dataset em um repositório público no GitHub: você pode armazenar seu dataset em um repositório público no GitHub e, em seguida, clonar o repositório no Colab usando o comando !git clone <link do repositório>. Assim, qualquer pessoa com acesso ao link público do Colab pode clonar o repositório e usar o dataset para treinar modelos."
      ],
      "metadata": {
        "id": "UBjK86iwVzkE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "HQJQf0mqV1kT"
      }
    }
  ]
}